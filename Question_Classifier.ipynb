{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import spacy \n",
    "import json \n",
    "from pandas.io.json import json_normalize\n",
    "from tqdm import tqdm \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 98/442 [01:40<05:51,  1.02s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-731994681946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paragraphs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mextracted_rows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'qas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate question data\n",
    "extracted_rows = []\n",
    "neg_examples = []\n",
    "\n",
    "\n",
    "# question text file into csv\n",
    "with open(\"train_5500.label.txt\", \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "    i = 0\n",
    "    for l in f.readlines():\n",
    "        split_line = l.split()\n",
    "        extracted_rows.append({\"text\": \" \".join(split_line[1:]), \"label\":1})\n",
    "pos_example = pd.DataFrame(extracted_rows)\n",
    "\n",
    "# statement & question text file into csv\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "data = json.load(open(\"train-v2.0.json\", \"r\"))\n",
    "data.keys()\n",
    "\n",
    "def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch.lower() for ch in text if ch not in exclude)\n",
    "\n",
    "import swifter\n",
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def clean_str(text: str) -> str:\n",
    "    return \" \".join([tok.lemma_ for tok in nlp(text)])\n",
    "\n",
    "for article in tqdm(data['data']):\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for sent in nlp(paragraph['context']).sents:\n",
    "            extracted_rows.append({\"text\": sent.text, \"label\": 0})\n",
    "        for i, question in enumerate(paragraph['qas']):\n",
    "            if i % 3 == 0:\n",
    "                extracted_rows.append({\"text\": remove_punc(question['question']), \"label\": 1})\n",
    "            else:\n",
    "                extracted_rows.append({\"text\": question['question'], \"label\": 1})\n",
    "\n",
    "for i in tqdm(range(0, len(extracted_rows))):\n",
    "    extracted_rows[i]['text'] = clean_str(extracted_rows[i]['text'])\n",
    "    \n",
    "# statement text file into csv            \n",
    "data2 = json.load(open(\"dev-v2.0.json\", \"r\"))\n",
    "\n",
    "for article in tqdm(data2['data']):\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for sent in nlp(paragraph['context']).sents:\n",
    "            extracted_rows.append({\"text\": sent.text, \"label\": 0})\n",
    "\n",
    "\n",
    "table = pd.DataFrame(extracted_rows)\n",
    "table.to_csv(\"qa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2693ddefba0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'table' is not defined"
     ]
    }
   ],
   "source": [
    "table.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8947b4f75955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make a model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# make a model \n",
    "train, test = train_test_split(table, stratify = table['label'], random_state = 75)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(table['text'])\n",
    "\n",
    "X_train = tfidf.transform(train['text'])\n",
    "X_test = tfidf.transform(test['text'])\n",
    "\n",
    "print(train.groupby(['label']).count())\n",
    "test.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83     26036\n",
      "           1       0.83      0.95      0.89     32580\n",
      "\n",
      "    accuracy                           0.86     58616\n",
      "   macro avg       0.88      0.85      0.86     58616\n",
      "weighted avg       0.87      0.86      0.86     58616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# multinomial fitting \n",
    "clf = MultinomialNB(alpha = 0.6)\n",
    "clf.fit(X_train, train['label'])\n",
    "clf.score(X_train, train['label'])\n",
    "\n",
    "mpreds = clf.predict(X_test)\n",
    "print(classification_report(test['label'], mpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     26036\n",
      "           1       0.98      0.98      0.98     32580\n",
      "\n",
      "    accuracy                           0.98     58616\n",
      "   macro avg       0.98      0.98      0.98     58616\n",
      "weighted avg       0.98      0.98      0.98     58616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# logistic regression fitting\n",
    "lclf = LogisticRegression()\n",
    "lclf.fit(X_train, train['label'])\n",
    "lclf.score(X_train, train['label'])\n",
    "\n",
    "lpreds = lclf.predict(X_test)\n",
    "print(classification_report(test['label'], lpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d5ccfa30c453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlrclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlrclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlrclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Linear Regression \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lrclf = LinearRegression()\n",
    "lrclf.fit(X_train, train['label'])\n",
    "lrclf.score(X_train, train['label'])\n",
    "\n",
    "lrpreds = lrclf.predict(X_test)\n",
    "print(classification_report(test['label'], lrpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95     26036\n",
      "           1       0.96      0.96      0.96     32580\n",
      "\n",
      "    accuracy                           0.96     58616\n",
      "   macro avg       0.96      0.96      0.96     58616\n",
      "weighted avg       0.96      0.96      0.96     58616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rclf = RandomForestClassifier()\n",
    "rclf.fit(X_train, train['label'])\n",
    "rclf.score(X_train, train['label'])\n",
    "\n",
    "rpreds = rclf.predict(X_test)\n",
    "print(classification_report(test['label'], rpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# apply model to posh data\n",
    "message = pd.read_csv(\"all_user_questions.csv\")\n",
    "message['message'] = message['message'].apply(lambda x: str(x)) \n",
    "\n",
    "m_encoded = tfidf.transform(message['message'].tolist())\n",
    "\n",
    "# get predictions and scores\n",
    "preds = lclf.predict(m_encoded)\n",
    "scores = lclf.predict_proba(m_encoded)\n",
    " \n",
    "message[\"is_question\"] = preds\n",
    "message['is_question_score'] = np.max(scores, axis = 1)\n",
    "\n",
    "# get random sample and export to csv\n",
    "m2 = message.sample(n=300, random_state = 2000)\n",
    "m2.to_csv(\"sample.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90       181\n",
      "           1       0.80      0.95      0.87       119\n",
      "\n",
      "    accuracy                           0.88       300\n",
      "   macro avg       0.88      0.89      0.88       300\n",
      "weighted avg       0.90      0.88      0.88       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get classification report\n",
    "ms = pd.read_csv(\"sample2.csv\")\n",
    "print(classification_report(ms['is_question'], ms['gold_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# apply model to posh data\n",
    "message = pd.read_csv(\"all_user_questions.csv\")\n",
    "message['message'] = message['message'].apply(lambda x: str(x)) \n",
    "\n",
    "m_encoded = tfidf.transform(message['message'].tolist())\n",
    "\n",
    "# get predictions and scores\n",
    "preds = rclf.predict(m_encoded)\n",
    "scores = rclf.predict_proba(m_encoded)\n",
    " \n",
    "message[\"is_question\"] = preds\n",
    "message['is_question_score'] = np.max(scores, axis = 1)\n",
    "\n",
    "# get random sample and export to csv\n",
    "m2 = message.sample(n=300, random_state = 2000)\n",
    "m2.to_csv(\"rsample.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       162\n",
      "           1       0.81      0.83      0.82       138\n",
      "\n",
      "    accuracy                           0.83       300\n",
      "   macro avg       0.83      0.83      0.83       300\n",
      "weighted avg       0.83      0.83      0.83       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ms = pd.read_csv(\"rsample2.csv\")\n",
    "print(classification_report(ms['is_question'], ms['gold_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234463/234463 [28:32<00:00, 136.88it/s] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(extracted_rows))):\n",
    "    extracted_rows[i]['text'] = clean_str(extracted_rows[i]['text'])\n",
    "\n",
    "table = pd.DataFrame(extracted_rows)\n",
    "table.to_csv(\"qa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 21981/21981 [2:10:33<00:00,  2.81it/s]  \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "X_train_bert = model.encode(train['text'].tolist(), show_progress_bar = True)\n",
    "Y_train_bert = train['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   48.8s finished\n",
      "Batches: 100%|██████████| 7327/7327 [38:40<00:00,  3.16it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test_bert' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-46b5d5ae9a2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mY_test_bert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_bert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_bert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test_bert' is not defined"
     ]
    }
   ],
   "source": [
    "# logistic regression fitting\n",
    "rclf = RandomForestClassifier(verbose = True, n_jobs = -1)\n",
    "rclf.fit(X_train_bert, Y_train_bert)\n",
    "\n",
    "X_test_bert = model.encode(test['text'].tolist(), show_progress_bar = True)\n",
    "Y_test_bert = test['label']\n",
    "\n",
    "print(classification_report(Y_test_bert, rclf.predict(X_test_bert)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90     26036\n",
      "           1       0.94      0.90      0.92     32580\n",
      "\n",
      "    accuracy                           0.91     58616\n",
      "   macro avg       0.91      0.91      0.91     58616\n",
      "weighted avg       0.91      0.91      0.91     58616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test_bert, rclf.predict(X_test_bert)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
