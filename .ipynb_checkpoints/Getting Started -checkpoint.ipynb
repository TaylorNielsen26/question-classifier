{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import spacy \n",
    "import json \n",
    "from pandas.io.json import json_normalize\n",
    "from tqdm import tqdm \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [07:51<00:00,  1.07s/it]\n",
      "100%|██████████| 35/35 [00:25<00:00,  1.39it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lower' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c52b67dba1be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mextracted_rows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"qa.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lower' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate question data\n",
    "rows = []\n",
    "neg_examples = []\n",
    "\n",
    "\n",
    "# question text file into csv\n",
    "with open(\"train_5500.label.txt\", \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "    i = 0\n",
    "    for l in f.readlines():\n",
    "        split_line = l.split()\n",
    "        rows.append({\"text\": \" \".join(split_line[1:]), \"label\":1})\n",
    "pos_example = pd.DataFrame(rows)\n",
    "pd.DataFrame(rows).to_csv(\"question_dataset.csv\", index = False)\n",
    "\n",
    "# statement & question text file into csv\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "data = json.load(open(\"train-v2.0.json\", \"r\"))\n",
    "data.keys()\n",
    "extracted_rows = []\n",
    "\n",
    "for article in tqdm(data['data']):\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for sent in nlp(paragraph['context']).sents:\n",
    "            extracted_rows.append({\"text\": sent.text, \"label\": 0})\n",
    "        for question in paragraph['qas']:\n",
    "            extracted_rows.append({\"text\": question['question'], \"label\": 1})\n",
    "\n",
    "# statement text file into csv            \n",
    "data2 = json.load(open(\"dev-v2.0.json\", \"r\"))\n",
    "\n",
    "for article in tqdm(data2['data']):\n",
    "    for paragraph in article['paragraphs']:\n",
    "        for sent in nlp(paragraph['context']).sents:\n",
    "            extracted_rows.append({\"text\": sent.text, \"label\": 0})\n",
    "\n",
    "table = pd.DataFrame(extracted_rows)\n",
    "table.to_csv(\"qa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>104144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>130319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text\n",
       "label        \n",
       "0      104144\n",
       "1      130319"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(extracted_rows)\n",
    "table.to_csv(\"qa.csv\")\n",
    "table.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        text\n",
      "label       \n",
      "0      78108\n",
      "1      97739\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>26036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "label       \n",
       "0      26036\n",
       "1      32580"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a model \n",
    "train, test = train_test_split(table, stratify = table['label'], random_state = 75)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(table['text'])\n",
    "\n",
    "X_train = tfidf.transform(train['text'])\n",
    "X_test = tfidf.transform(test['text'])\n",
    "\n",
    "print(train.groupby(['label']).count())\n",
    "test.groupby(['label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85     26036\n",
      "           1       0.85      0.95      0.89     32580\n",
      "\n",
      "    accuracy                           0.88     58616\n",
      "   macro avg       0.88      0.87      0.87     58616\n",
      "weighted avg       0.88      0.88      0.87     58616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# multinomial fitting \n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, train['label'])\n",
    "clf.score(X_train, train['label'])\n",
    "\n",
    "mpreds = clf.predict(X_test)\n",
    "print(classification_report(test['label'], mpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     26036\n",
      "           1       0.98      0.98      0.98     32580\n",
      "\n",
      "    accuracy                           0.98     58616\n",
      "   macro avg       0.98      0.98      0.98     58616\n",
      "weighted avg       0.98      0.98      0.98     58616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# logistic regression fitting\n",
    "lclf = LogisticRegression()\n",
    "lclf.fit(X_train, train['label'])\n",
    "lclf.score(X_train, train['label'])\n",
    "\n",
    "lpreds = lclf.predict(X_test)\n",
    "print(classification_report(test['label'], lpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96     26036\n",
      "           1       0.96      0.97      0.96     32580\n",
      "\n",
      "    accuracy                           0.96     58616\n",
      "   macro avg       0.96      0.96      0.96     58616\n",
      "weighted avg       0.96      0.96      0.96     58616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rclf = RandomForestClassifier()\n",
    "rclf.fit(X_train, train['label'])\n",
    "rclf.score(X_train, train['label'])\n",
    "\n",
    "rpreds = rclf.predict(X_test)\n",
    "print(classification_report(test['label'], rpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78155/78155 [23:50<00:00, 54.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# remove punctuation from every third entry and lower all text for all entries\n",
    "import string\n",
    "def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch.lower() for ch in text if ch not in exclude)\n",
    "\n",
    "for i in tqdm(range(0, len(table), 3)):\n",
    "    table['text'].iloc[i] = remove_punc(table['text'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 29995/234463 [15:39<3:58:02, 14.32it/s]"
     ]
    }
   ],
   "source": [
    "import swifter\n",
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def clean_str(text: str) -> str:\n",
    "    return \" \".join([tok.lemma_ for tok in nlp(text)])\n",
    "\n",
    "for i in tqdm(range(0, len(table))):\n",
    "    table['text'].iloc[i] = clean_str(table['text'].iloc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89       184\n",
      "           1       0.77      0.94      0.85       116\n",
      "\n",
      "    accuracy                           0.87       300\n",
      "   macro avg       0.86      0.88      0.87       300\n",
      "weighted avg       0.89      0.87      0.87       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# apply model to posh data\n",
    "message = pd.read_csv(\"all_user_questions.csv\")\n",
    "message['message'] = message['message'].apply(lambda x: str(x)) \n",
    "\n",
    "m_encoded = tfidf.transform(message['message'].tolist())\n",
    "\n",
    "# get predictions and scores\n",
    "preds = lclf.predict(m_encoded)\n",
    "scores = lclf.predict_proba(m_encoded)\n",
    " \n",
    "message[\"is_question\"] = preds\n",
    "message['is_question_score'] = np.max(scores, axis = 1)\n",
    "\n",
    "# get random sample and export to csv\n",
    "m2 = message.sample(n=300, random_state = 2000)\n",
    "m2.to_csv(\"sample.csv\")\n",
    "\n",
    "# get classification report\n",
    "ms = pd.read_csv(\"sample2.csv\")\n",
    "print(classification_report(ms['is_question'], ms['gold_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
